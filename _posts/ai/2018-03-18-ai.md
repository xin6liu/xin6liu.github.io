---
layout: post
title: 神经网络
date: 2018-03-18
category: ai
description: 
---

## 回归问题与分类问题

Regression: 
目的：输入x，预测输出y。
y随x连续变化。

Classification:
事先给定若干类别，输入X判断属于哪个类别。
输出y是离散的。

## 有监督学习和无监督学习

有监督：
事先给出了正确答案。

无监督：
主要用于cluster，将X分为多个类别，同一类别行为相似。但事先并不知道会划分多少类别，每个类别的特点是什么。

## 模型的构建 -- 神经网络

要让机器 “学习”，一般需要：
1. 用来解决问题的模型 `model`
2. 学习数据（或者说训练数据）`data`
3. 让模型model通过数据data学会解决特定问题的学习算法 `learn`


![](https://dn-anything-about-doc.qbox.me/document-uid49570labid2864timestamp1493273626507.png)

神经元间相连的线上有该条连接线的权重w, 神经网络工作时，将前一层网络中的每个神经元的值，与连接线上的权重w相乘，传递给下一层网络中的神经元。同时，每个神经元还会接收一个偏移量(bias)。

```
w11*a1+w12*a2+w13*a3 + bias1=b1
w21*a1+w22*a2+w23*a3 + bias2=b2
```

对于网络层2中的神经元b，它的值在传给输出之前, 会先经过一次非线性运算g(图中没有画出来)

```
g(b1)=Y1  
g(b2)=Y2
```

## 非线性激活函数

上面提到的非线性运算 g 称为激活函数。最经典的一种激活函数：sigmoid激活函数：

$ g(x) = \frac{1}{1+e^{-x}} $ 

![](https://dn-anything-about-doc.qbox.me/document-uid49570labid2864timestamp1493102593501.png)

即输入值x越大，函数值越接近 1，输入值越小，函数值越接近 0，当输入为 0 的时候，函数值为 0.5。

引用非线性函数的作用：

1. 如果没有非线性运算部分，那么由于矩阵乘法的结合性, 多个线性运算层直接相连的效果实际上相当于只进行了一次线性运算，多层次的网络结构失去了意义。


2. 例如，分类算法：`w11*a1+w12*a2 + bias1=b1` 对于输入a, 当最终得到的b1大于 0 时，我们认为a属于b1所代表的的类别，否则不属于b1所代表的的类别。不同类别之间的分界线不是直线而是曲线，此时无论如何也无法用线性分类器去准确的进行分类。 而非线性部分的引入，在一定程度上可以使原本的直线变成曲线。

## 评价神经网络的效果

比较神经网络的输出h与预期的正确输出y之间的差异,比如计算(h-y)^2。

最经典的一种损失函数（cost function）：二次损失函数（quadratic loss function）。

$$ J(\theta) = [h(\theta, X) - Y]^2 $$

其实，这里`学习算法learn`按照某种策略，通过不断的更新参数值来使损失函数$J(\theta,X,Y)$的值减小, theta是不断变化的量, 也就是自变量，而X,Y可以看做常量。


## 梯度下降算法：

$$ \Theta = \Theta - \alpha \frac{dJ}{d \theta} $$

Alpha 是一个超参数，手动设定。表示下降的步长，被称为学习速率。


