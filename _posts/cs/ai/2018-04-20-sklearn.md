---
layout: post
title: 分类和回归
date: 2018-04-20
category: ai
---

如果说，监督学习有两大基本类型：分类和回归（事实上还有序列化标注等更加复杂的问题）；那么无监督学习有：聚类、降维等问题。

1.1-1.4：分类
1.5：回归

## 1.1 线性分类器
上节讲的 logistic regression 和 SGD分类器

## 1.2 SVM 分类器
一般而言，基于的也是线性假设。但是由于可以引入一些核技巧(kernel trick)，可以将特征映射到更加高维度，甚至非线性的空间上，从而使数据空间变得更加可分。

这个分类器适合于直接做分类，不适合做分类概率的估计。
经典问题：AT&T 400张人脸


## 1.3 朴素贝叶斯分类器（Naive Bayes)
文本分类


## 1.4 决策树分类器（Decision Tree) / 集成分类器（Ensemble Tree）
1. 非线性的分类器
2. 即便使用类似SVM的分类器，我们很难得到明确分类“依据”的说明，无法“解释”分类器是如何工作的，特别无法从人类逻辑的角度理解。高维度、不可解释性等，这些都是弊端。

问题：Titanic

## 1.5 回归问题（Regressions）
回归问题和分类问题都同属于监督学习范畴，唯一不同的是，回归问题的预测目标是在无限的连续实数域，比如预测房价、股票价格等等；分类问题则是对有限范围的几个类别（离散数）进行预测。当然两者的界限不一定泾渭分明，也可以适度转化。比如，有一个经典的对红酒质量的预测，大体分为10等级，怎样看待这个预测目标，都是可以的。预测的结果，可以在（0-10]区间连续（回归问题），也可以只预测10个等级的某个值（分类问题）。
经典问题：波士顿地区房价。