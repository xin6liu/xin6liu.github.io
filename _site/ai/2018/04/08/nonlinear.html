<!DOCTYPE html>

<html>

<head>
	<title>LiuXin</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<!--[if lte IE 8]><script src="http://localhost:4000/assets/js/ie/html5shiv.js"></script><![endif]-->
	<link rel="stylesheet" href="/assets/css/main.css">
	<!--[if lte IE 9]><link rel="stylesheet" href="http://localhost:4000/assets/css/ie9.css" /><![endif]-->
	<!--[if lte IE 8]><link rel="stylesheet" href="http://localhost:4000/assets/css/ie8.css" /><![endif]-->
	<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>


<body>

<!-- Wrapper -->
<div id="wrapper">

<!-- Header -->
<header id="header"	
					>
	<a href="http://localhost:4000/" class="logo"><strong>LiuXin</strong> <span>stay hungry, stay foolish</span></a>
	<nav>
		<a href="#menu">Menu</a>
	</nav>
</header>

<!-- Menu -->
<nav id="menu">
	<ul class="links">
        
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		        <li><a href="http://localhost:4000/">Home</a></li>
	    	
		
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		
		
		    
		        <li><a href="http://localhost:4000/%E4%B8%BB%E9%A1%B5/1python.html">Python</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E4%B8%BB%E9%A1%B5/2ai.html">机器学习 Machine Learning</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E4%B8%BB%E9%A1%B5/3cfd.html">计算流体力学 CFD</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E4%B8%BB%E9%A1%B5/4cs.html">计算机科学 Computer Science</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E4%B8%BB%E9%A1%B5/5mns.html">纳米材料与技术 Materials and Nanoscience</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E4%B8%BB%E9%A1%B5/6course.html">课程 Course</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E4%B8%BB%E9%A1%B5/7diary.html">生活 Diary</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E4%B8%BB%E9%A1%B5/8categories.html">总目录 Categories</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/file/3cfd/%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/PDE">PDE</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E7%9B%AE%E5%BD%95catalog/%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/PDE/PDE%E5%9F%BA%E7%A1%80">PDE基础</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/file/about.html">我的故事 My Stories</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/file/category.html">目录 Category</a></li>
		    
		
		    
		
		    
		        <li><a href="http://localhost:4000/file/3cfd/%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/%E5%8F%98%E5%88%86%E6%B3%95">变分法</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/file/3cfd/%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/%E6%9C%89%E9%99%90%E4%BD%93%E7%A7%AF%E6%B3%95">有限体积法</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E7%9B%AE%E5%BD%95catalog/%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/%E6%9C%89%E9%99%90%E5%85%83%E6%B3%95">有限元法</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E7%9B%AE%E5%BD%95catalog/%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6">流体力学</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E7%9B%AE%E5%BD%95catalog/%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/%E6%9C%89%E9%99%90%E4%BD%93%E7%A7%AF%E6%B3%95/%E7%A6%BB%E6%95%A3%E6%96%B9%E6%B3%95">离散方法</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E7%9B%AE%E5%BD%95catalog/%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/%E8%BF%9E%E7%BB%AD%E4%BB%8B%E8%B4%A8%E5%8A%9B%E5%AD%A6">连续介质力学</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E7%9B%AE%E5%BD%95catalog/%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/%E6%9C%89%E9%99%90%E4%BD%93%E7%A7%AF%E6%B3%95/%E9%80%9F%E5%BA%A6%E5%8E%8B%E5%8A%9B%E8%80%A6%E5%90%88%E6%96%B9%E6%B3%95">速度压力耦合方法</a></li>
		    
		
	</ul>
	<ul class="actions vertical">
		<li><a href="#" class="button special fit">Get Started</a></li>
		<li><a href="#" class="button fit">Log In</a></li>
	</ul>
</nav> 
    
    
<!-- Main -->
<div id="main" class="alt">

<!-- One -->
<section id="one">
	<div class="inner">
		<header class="major">
<!-- title -->
			<h1>非线性回归</h1>
<!-- 日期 -->		
		
		2018-04-08
		
		</header>
<!-- description -->	
		<h5></h5>
<!-- 图片 -->		
		<!-- 
		 -->
<!-- 正文 -->
		<p><blockquote>
  <p>vscode 小技巧：
Shift + Alt + I, 在选定的每一行的末尾插入光标</p>
</blockquote>

<h3 id="1-数据集描述和加载">1 数据集描述和加载</h3>

<p>本例中，我们使用生成的数据集，这跟书中第三章线性回归类似。</p>

<p>我们这次选择的方程是一个二次方程，并加上随机噪声，这有助于帮助我们测试回归的泛化能力。</p>

<p>核心代码如下：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="n">trainsamples</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">testsamples</span> <span class="o">=</span> <span class="mi">60</span>
<span class="n">dsX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">trainsamples</span> <span class="o">+</span> <span class="n">testsamples</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
<span class="n">dsY</span> <span class="o">=</span> <span class="mf">0.4</span><span class="o">*</span> <span class="nb">pow</span><span class="p">(</span><span class="n">dsX</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span><span class="mi">2</span> <span class="o">*</span> <span class="n">dsX</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">dsX</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.22</span> <span class="o">+</span> <span class="mf">0.8</span>
</code></pre></div></div>
<h3 id="2-数据集预处理">2 数据集预处理</h3>

<p>本例中的数据集不需要预处理，因为它是我们人工生成的，具有更好的性能，比如能够保证数据范围是 $ (-1,1) $ 。</p>
<h3 id="3-模型结构损失函数描述">3 模型结构——损失函数描述</h3>

<p>本例中的损失函数使用均方误差，由以下代码实现：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="nb">pow</span><span class="p">(</span><span class="n">py_x</span><span class="o">-</span><span class="n">Y</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
</code></pre></div></div>
<h3 id="4-损失函数优化器">4 损失函数优化器</h3>

<p>本例中，我们使用梯度下降作为损失函数优化器，可以用以下代码实现：</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="mf">0.5</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
</code></pre></div></div>
<h3 id="5-准确度和收敛测试">5 准确度和收敛测试</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">predict_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">py_x</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
<span class="n">cost1</span> <span class="o">+=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="p">[[</span><span class="n">x1</span><span class="p">]],</span> <span class="n">Y</span><span class="p">:</span> <span class="n">y1</span><span class="p">})</span> <span class="o">/</span> <span class="n">testsamples</span>
</code></pre></div></div>
<h3 id="6-完整源代码如下">6 完整源代码如下</h3>

<p>因为需要在 $ Jupyter\ Notebook $ 中执行，下文中的代码为使其能够在实验楼环境中运行会对原书的内容进行一些细微的更改。</p>

<p><strong>☞ 示例代码：</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="n">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="nn">sklearn.utils</span> <span class="kn">import</span> <span class="n">shuffle</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span> 
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>


<span class="n">trainsamples</span> <span class="o">=</span> <span class="mi">200</span>
<span class="n">testsamples</span> <span class="o">=</span> <span class="mi">60</span>

<span class="c"># 这里我们定义模型。这个模型中含有一个简单的输入层和一个隐藏的sigmoid激活层。</span>
<span class="k">def</span> <span class="nf">model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">hidden_weights1</span><span class="p">,</span> <span class="n">hidden_bias1</span><span class="p">,</span> <span class="n">ow</span><span class="p">):</span>
    <span class="n">hidden_layer</span> <span class="o">=</span>  <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">sigmoid</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">hidden_weights1</span><span class="p">)</span><span class="o">+</span> <span class="n">b</span><span class="p">)</span> 
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">hidden_layer</span><span class="p">,</span> <span class="n">ow</span><span class="p">)</span>

<span class="c"># 随机生成数据</span>
<span class="n">dsX</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">trainsamples</span> <span class="o">+</span> <span class="n">testsamples</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span> <span class="c"># 在-1到1内返回均匀间隔的数字</span>
<span class="n">dsY</span> <span class="o">=</span> <span class="mf">0.4</span><span class="o">*</span> <span class="nb">pow</span><span class="p">(</span><span class="n">dsX</span><span class="p">,</span><span class="mi">2</span><span class="p">)</span> <span class="o">+</span><span class="mi">2</span> <span class="o">*</span> <span class="n">dsX</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="o">*</span><span class="n">dsX</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span> <span class="o">*</span> <span class="mf">0.22</span> <span class="o">+</span> <span class="mf">0.8</span> <span class="c"># 生成Y方向的值</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">()</span> <span class="c"># 创建输出文件</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s">'Original data'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">dsX</span><span class="p">,</span><span class="n">dsY</span><span class="p">)</span> <span class="c"># 绘制数据点的散点图</span>
</code></pre></div></div>
<p><strong>☞ 动手练习：</strong>
<strong>☞ 示例代码：</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="s">"float"</span><span class="p">)</span>
<span class="n">Y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="s">"float"</span><span class="p">)</span>

<span class="c"># 创建第一个隐藏层</span>
<span class="n">hw1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">10</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">))</span>
<span class="c"># 创建输出连接</span>
<span class="n">ow</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">))</span>
<span class="c"># 产生误差</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random_normal</span><span class="p">([</span><span class="mi">10</span><span class="p">],</span> <span class="n">stddev</span><span class="o">=</span><span class="mf">0.01</span><span class="p">))</span>

<span class="n">model_y</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">hw1</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">ow</span><span class="p">)</span>
<span class="c"># 损失函数</span>
<span class="n">cost</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="nb">pow</span><span class="p">(</span><span class="n">model_y</span><span class="o">-</span><span class="n">Y</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span><span class="o">/</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>
<span class="c"># 创建优化器</span>
<span class="n">train_op</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">train</span><span class="o">.</span><span class="n">AdamOptimizer</span><span class="p">(</span><span class="mf">0.0001</span><span class="p">)</span><span class="o">.</span><span class="n">minimize</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
</code></pre></div></div>
<p><strong>☞ 动手练习：</strong>
<strong>☞ 示例代码：</strong></p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># 在进程中启动</span>
<span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">Session</span><span class="p">()</span> <span class="k">as</span> <span class="n">sess</span><span class="p">:</span>
    <span class="n">tf</span><span class="o">.</span><span class="n">global_variables_initializer</span><span class="o">.</span><span class="n">run</span><span class="p">()</span> <span class="c"># 初始化所有变量</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span> <span class="o">=</span><span class="n">dsX</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">trainsamples</span><span class="p">],</span> <span class="n">dsY</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">trainsamples</span><span class="p">]</span> <span class="c"># 对样本进行随机抽样保证有较好的训练效果</span>
        <span class="k">for</span> <span class="n">x1</span><span class="p">,</span><span class="n">y1</span> <span class="ow">in</span> <span class="nb">zip</span> <span class="p">(</span><span class="n">trainX</span><span class="p">,</span> <span class="n">trainY</span><span class="p">):</span>
            <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">train_op</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="p">[[</span><span class="n">x1</span><span class="p">]],</span> <span class="n">Y</span><span class="p">:</span> <span class="n">y1</span><span class="p">})</span>
        <span class="n">testX</span><span class="p">,</span> <span class="n">testY</span> <span class="o">=</span> <span class="n">dsX</span><span class="p">[</span><span class="n">trainsamples</span><span class="p">:</span><span class="n">trainsamples</span> <span class="o">+</span> <span class="n">testsamples</span><span class="p">],</span> <span class="n">dsY</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="n">trainsamples</span><span class="p">:</span><span class="n">trainsamples</span><span class="o">+</span><span class="n">testsamples</span><span class="p">]</span>
        <span class="n">cost1</span><span class="o">=</span><span class="mf">0.</span>
        <span class="k">for</span> <span class="n">x1</span><span class="p">,</span><span class="n">y1</span> <span class="ow">in</span> <span class="nb">zip</span> <span class="p">(</span><span class="n">testX</span><span class="p">,</span> <span class="n">testY</span><span class="p">):</span>
            <span class="n">cost1</span> <span class="o">+=</span> <span class="n">sess</span><span class="o">.</span><span class="n">run</span><span class="p">(</span><span class="n">cost</span><span class="p">,</span> <span class="n">feed_dict</span><span class="o">=</span><span class="p">{</span><span class="n">X</span><span class="p">:</span> <span class="p">[[</span><span class="n">x1</span><span class="p">]],</span> <span class="n">Y</span><span class="p">:</span> <span class="n">y1</span><span class="p">})</span> <span class="o">/</span> <span class="n">testsamples</span>       
            <span class="k">print</span><span class="p">(</span> <span class="s">" Average cost for epoch "</span> <span class="o">+</span> <span class="nb">str</span> <span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="o">+</span> <span class="s">":"</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">cost1</span><span class="p">))</span>
        <span class="n">dsX</span><span class="p">,</span> <span class="n">dsY</span> <span class="o">=</span> <span class="n">shuffle</span> <span class="p">(</span><span class="n">dsX</span><span class="p">,</span> <span class="n">dsY</span><span class="p">)</span> <span class="c"># 我们随机抽样来实施更好的训练</span>
</code></pre></div></div>
<p><strong>☞ 动手练习：</strong></p>
<h3 id="6-结果描述">6 结果描述</h3>

<p>生成的人工数据的散点图如下图所示。</p>

<p><img src="attachment:%E4%BA%BA%E5%B7%A5%E6%95%B0%E6%8D%AE%E6%95%A3%E7%82%B9%E5%9B%BE.png" alt="人工数据散点图" /></p>

<p>由以下每次迭代的结果，我们知道该实现结果非常好，甚至在第一次迭代的时候就取得了不错的结果。</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Average cost for epoch 1:[[ 0.00753353]]
Average cost for epoch 2:[[ 0.00381996]]
Average cost for epoch 3:[[ 0.00134867]]
Average cost for epoch 4:[[ 0.01020064]]
Average cost for epoch 5:[[ 0.00240157]]
Average cost for epoch 6:[[ 0.01248318]]
Average cost for epoch 7:[[ 0.05143405]]
Average cost for epoch 8:[[ 0.00621457]]
Average cost for epoch 9:[[ 0.00073790]]
</code></pre></div></div>

<p>注：因为自动生成的数据不同，每次运行的结果可能并不一样。</p>
<h2 id="五实验总结">五、实验总结</h2>

<p>本文通过对非线性数据进行回归分析，初步展现了向前神经网络的功能。在上述实验中，用向前神经网络计算模型，很快就获得了良好的结果，在之后的实验中我们将逐步扩大模型。</p>
<h2 id="六扩展阅读">六、扩展阅读</h2>

<p>本课程源自 <a href="http://www.epubit.com.cn/">异步社区</a> 的 <a href="http://www.epubit.com.cn/book/details/4797">《TensorFlow机器学习项目实战》</a> 第 $ 5 $ 章，再次感谢 <a href="http://www.epubit.com.cn/">异步社区</a> 授权实验楼发布。</p>

<p>如果学完本课程，对书籍其他内容感兴趣欢迎点击以下链接购买书籍：</p>

<ul>
  <li><a href="https://item.jd.com/12235801.html">立即购买《TensorFlow机器学习项目实战》</a></li>
</ul>
<div style="color: #999;font-size: 12px;font-style: italic;">*本课程内容，由作者授权实验楼发布，未经允许，禁止转载、下载及非法传播。&lt;/div
</div>
</p>
	</div>

</section>
</div>


<!-- Footer -->
	<footer id="footer">
		<div class="inner">
			<ul class="icons">
				
				
				<li><a href="http://weibo.com/u/2377304267" class="icon alt fa-weibo" target="_blank"><span class="label">weibo</span></a></li>
				
				
				<li><a href="https://www.facebook.com/profile.php?id=100009585159226" class="icon alt fa-facebook" target="_blank"><span class="label">Facebook</span></a></li>
				
				
				<li><a href="https://www.instagram.com/harryliuxin/" class="icon alt fa-instagram" target="_blank"><span class="label">Instagram</span></a></li>
				
				
				
				
				
				<li><a href="http://www.miaopai.com/u/wxsso_p4mslofx14" class="icon alt fa-video-camera" target="_blank"><span class="label">video</span></a></li>
				
				
				<li><a href="https://www.linkedin.com/in/xin-liu-868501134" class="icon alt fa-linkedin" target="_blank"><span class="label">LinkedIn</span></a></li>
				
			</ul>
			<ul class="copyright">
				<li>&copy; LiuXin </li>
				<li> stay hungry, stay foolish</li>
				<li>Designed by: <a href="https://liuxin.in/about/" target="_blank">刘鑫</a></li>

			</ul>
		</div>
	</footer>

	

</body>

</html>