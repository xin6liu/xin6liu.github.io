<!DOCTYPE html>

<html>

<head>
	<title>LiuXin</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<!--[if lte IE 8]><script src="http://localhost:4000/assets/js/ie/html5shiv.js"></script><![endif]-->
	<link rel="stylesheet" href="/assets/css/main_new.css">
	<link rel="stylesheet" href="/assets/css/syntax.css">
	<!--[if lte IE 9]><link rel="stylesheet" href="http://localhost:4000/assets/css/ie9.css" /><![endif]-->
	<!--[if lte IE 8]><link rel="stylesheet" href="http://localhost:4000/assets/css/ie8.css" /><![endif]-->
	<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>


<body>

<!-- Wrapper -->
<div id="wrapper">

<!-- Header -->
<header id="header"	
					>
	<a href="http://localhost:4000/" class="logo"><strong>LiuXin</strong> <span>stay hungry, stay foolish</span></a>
	<nav>
		<a href="#menu">Menu</a>
	</nav>
</header>

<!-- Menu -->
<nav id="menu">
	<ul class="links">
		
		
			
				<li><a href="/home/1python.html">网页开发 Web Development</a></li>
			
		
			
				<li><a href="/home/2ai.html">机器学习 Machine Learning</a></li>
			
		
			
				<li><a href="/home/3cfd.html">计算流体力学 CFD</a></li>
			
		
			
				<li><a href="/home/4cs.html">计算机科学 Computer Science</a></li>
			
		
			
				<li><a href="/home/5mns.html">纳米科学 Nanoscience</a></li>
			
		
			
				<li><a href="/home/6course.html">课程 Course</a></li>
			
		
			
				<li><a href="/home/7diary.html">生活 Diary</a></li>
			
		
			
				<li><a href="/home/8categories.html">总目录 Categories</a></li>
			
		
	</ul>
	<!-- <ul class="actions vertical">
		<li><a href="#" class="button special fit">Get Started</a></li>
		<li><a href="#" class="button fit">Log In</a></li>
	</ul> -->
</nav> 
    
    
<!-- Main -->
<div id="main" class="alt">

<!-- One -->
<section id="one">
	<div class="inner">
		<header class="major">
<!-- title -->
			<h1>深度学习</h1>
<!-- 日期 -->		
		
		2018-04-30
		
		</header>
<!-- description -->	
		<h5></h5>
<!-- 图片 -->		
		<!-- 
		 -->
<!-- 正文 -->
		<p><ul>
  <li>Hyperparameter tuning</li>
  <li>Regularization</li>
  <li>
    <p>Optimization</p>
  </li>
  <li>Diagnose price and variants</li>
  <li>Advance optimization algorithms</li>
</ul>

<p>上角标代表example的个数，一共有m个</p>

<ul>
  <li>从train set error， 看 bias</li>
  <li>从train set error 和 dev set error 的差，看variance.</li>
</ul>

<p>L2 regularization</p>

<p>Frobenius norm: the sum of square of elements of a matrix</p>

<h3 id="weight-decay">“Weight decay”:</h3>
<p>以前是w-alpha*dw</p>

<p>现在是(1-alpha<em>lambda/m)</em>w-alpha*dw</p>

<p>Lambda 很大的话，w会变小，z也会变小。当z变小的时候，每一层都会接近linear.</p>

<p>D3 表示一个三层的dropout 向量：</p>

<p>d3 = np.random.rand(a3.shape[0], a3.shape[1])</p>

<h2 id="总结">总结：</h2>

<p>dev集的error太大 -&gt; variance太大 -&gt; 需要减少overfitting:</p>

<ol>
  <li>Regularization</li>
  <li>More training data</li>
</ol>

<p>High bias:</p>

<ol>
  <li>Deeper neural network</li>
  <li>Increase the number of units</li>
  <li>More test data</li>
</ol>

<h2 id="初始化">初始化</h2>

<p>如果W和b都初始为零的话，无论几次结果都一样</p>

<pre><code class="language-python">    for l in range(1, L):
        parameters['W' + str(l)] = np.zeros((layers_dims[l], layers_dims[l-1]))
        parameters['b' + str(l)] = np.zeros((layers_dims[l], 1))
</code></pre>

<p>如果W太大的话，刚开始cost会很大，运算慢，结果不好</p>

<pre><code class="language-python">    for l in range(1, L):
        parameters['W' + str(l)] = np.random.randn(layers_dims[l],layers_dims[l-1])*10
        parameters['b' + str(l)] = np.zeros((layers_dims[l],1))
</code></pre>

<p>He initialization: instead of multiplying <code>np.random.randn(..,..)</code> by 10, you will multiply it by $\sqrt{\frac{2}{\text{dimension of the previous layer}}}$</p>

<pre><code class="language-python">    for l in range(1, L):
        parameters['W' + str(l)] = np.random.randn(layers_dims[l],layers_dims[l-1])*np.sqrt(2/layers_dims[l-1])
        parameters['b' + str(l)] = np.zeros((layers_dims[l],1))
</code></pre>

<h2 id="adam-optimization-algorithm">Adam optimization algorithm:</h2>

<p>循环：
	利用 current mini batch 计算 dw, db 
	新的 Vdw 和 Vdb
	新的 Sdw 和 Sdb
	新的 Vdw^correct 和 Vdb^correct
	新的 Sdw^correct 和 Sdb^correct
	新的 W, b</p>

<p>需要使用 0.9 的加权数之前的数值加上当日温度的 0.1 倍</p>
</p>
	</div>

</section>
</div>


<!-- Footer -->
	<footer id="footer">
		<div class="inner">
			<ul class="icons">
				
				
				<li><a href="http://weibo.com/u/2377304267" class="icon alt fa-weibo" target="_blank"><span class="label">weibo</span></a></li>
				
				
				<li><a href="https://www.facebook.com/profile.php?id=100009585159226" class="icon alt fa-facebook" target="_blank"><span class="label">Facebook</span></a></li>
				
				
				<li><a href="https://www.instagram.com/harryliuxin/" class="icon alt fa-instagram" target="_blank"><span class="label">Instagram</span></a></li>
				
				
				
				
				
				<li><a href="http://www.miaopai.com/u/wxsso_p4mslofx14" class="icon alt fa-video-camera" target="_blank"><span class="label">video</span></a></li>
				
				
				<li><a href="https://www.linkedin.com/in/xin-liu-868501134" class="icon alt fa-linkedin" target="_blank"><span class="label">LinkedIn</span></a></li>
				
			</ul>
			<ul class="copyright">
				<li>&copy; LiuXin </li>
				<li> stay hungry, stay foolish</li>
				<li>Designed by: <a href="https://liuxin.in/about/" target="_blank">刘鑫</a></li>

			</ul>
		</div>
	</footer>

	

</body>

</html>