<!DOCTYPE html>

<html>

<head>
	<title>LiuXin</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<!--[if lte IE 8]><script src="http://localhost:4000/assets/js/ie/html5shiv.js"></script><![endif]-->
	<link rel="stylesheet" href="/assets/css/main_new.css">
	<!--[if lte IE 9]><link rel="stylesheet" href="http://localhost:4000/assets/css/ie9.css" /><![endif]-->
	<!--[if lte IE 8]><link rel="stylesheet" href="http://localhost:4000/assets/css/ie8.css" /><![endif]-->
	<script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</head>


<body>

<!-- Wrapper -->
<div id="wrapper">

<!-- Header -->
<header id="header"	
					>
	<a href="http://localhost:4000/" class="logo"><strong>LiuXin</strong> <span>stay hungry, stay foolish</span></a>
	<nav>
		<a href="#menu">Menu</a>
	</nav>
</header>

<!-- Menu -->
<nav id="menu">
	<ul class="links">
		<!-- 
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		
			
		 -->
        <!-- 
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		        <li><a href="http://localhost:4000/">Home</a></li>
	    	
		
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		
		    
		 -->
		
		
        
		<li><a href="http://localhost:4000/">网页开发 Web Development</a></li>
        
		
        
		<li><a href="http://localhost:4000/">机器学习 Machine Learning</a></li>
        
		
        
		<li><a href="http://localhost:4000/">计算流体力学 CFD</a></li>
        
		
        
		<li><a href="http://localhost:4000/">计算机科学 Computer Science</a></li>
        
		
        
		<li><a href="http://localhost:4000/">纳米科学 Nanoscience</a></li>
        
		
        
		<li><a href="http://localhost:4000/">课程 Course</a></li>
        
		
        
		<li><a href="http://localhost:4000/">生活 Diary</a></li>
        
		
        
		<li><a href="http://localhost:4000/">总目录 Categories</a></li>
        
		
		

		<!-- 
		    
		        <li><a href="http://localhost:4000/home/1python.html">网页开发 Web Development</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/home/2ai.html">机器学习 Machine Learning</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/home/3cfd.html">计算流体力学 CFD</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/home/4cs.html">计算机科学 Computer Science</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/home/5mns.html">纳米科学 Nanoscience</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/home/6course.html">课程 Course</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/home/7diary.html">生活 Diary</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/home/8categories.html">总目录 Categories</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/file/3cfd/%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/PDE">PDE</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E7%9B%AE%E5%BD%95catalog/%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/PDE/PDE%E5%9F%BA%E7%A1%80">PDE基础</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/file/about.html">我的故事 My Stories</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/file/category.html">目录 Category</a></li>
		    
		
		    
		
		    
		        <li><a href="http://localhost:4000/file/3cfd/%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/%E5%8F%98%E5%88%86%E6%B3%95">变分法</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/file/3cfd/%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/%E6%9C%89%E9%99%90%E4%BD%93%E7%A7%AF%E6%B3%95">有限体积法</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E7%9B%AE%E5%BD%95catalog/%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/%E6%9C%89%E9%99%90%E5%85%83%E6%B3%95">有限元法</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E7%9B%AE%E5%BD%95catalog/%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6">流体力学</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E7%9B%AE%E5%BD%95catalog/%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/%E6%9C%89%E9%99%90%E4%BD%93%E7%A7%AF%E6%B3%95/%E7%A6%BB%E6%95%A3%E6%96%B9%E6%B3%95">离散方法</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E7%9B%AE%E5%BD%95catalog/%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/%E8%BF%9E%E7%BB%AD%E4%BB%8B%E8%B4%A8%E5%8A%9B%E5%AD%A6">连续介质力学</a></li>
		    
		
		    
		        <li><a href="http://localhost:4000/%E7%9B%AE%E5%BD%95catalog/%E8%AE%A1%E7%AE%97%E6%B5%81%E4%BD%93%E5%8A%9B%E5%AD%A6/%E6%9C%89%E9%99%90%E4%BD%93%E7%A7%AF%E6%B3%95/%E9%80%9F%E5%BA%A6%E5%8E%8B%E5%8A%9B%E8%80%A6%E5%90%88%E6%96%B9%E6%B3%95">速度压力耦合方法</a></li>
		    
		 -->
	</ul>
	<!-- <ul class="actions vertical">
		<li><a href="#" class="button special fit">Get Started</a></li>
		<li><a href="#" class="button fit">Log In</a></li>
	</ul> -->
</nav> 
    
    
<!-- Main -->
<div id="main" class="alt">

<!-- One -->
<section id="one">
	<div class="inner">
		<header class="major">
<!-- title -->
			<h1>cnn</h1>
<!-- 日期 -->		
		
		2018-06-10
		
		</header>
<!-- description -->	
		<h5></h5>
<!-- 图片 -->		
		<!-- 
		 -->
<!-- 正文 -->
		<p><p>cross-correlation</p>

<p>convolution</p>

<script type="math/tex; mode=display">s(t) = \int x(a) w(t-a) da</script>

<h2 id="conv_forward">conv_forward</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># GRADED FUNCTION: conv_forward</span>

<span class="k">def</span> <span class="nf">conv_forward</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">):</span>
    <span class="s">"""
    Implements the forward propagation for a convolution function
    
    Arguments:
    A_prev -- output activations of the previous layer, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)
    W -- Weights, numpy array of shape (f, f, n_C_prev, n_C)
    b -- Biases, numpy array of shape (1, 1, 1, n_C)
    hparameters -- python dictionary containing "stride" and "pad"
        
    Returns:
    Z -- conv output, numpy array of shape (m, n_H, n_W, n_C)
    cache -- cache of values needed for the conv_backward() function
    """</span>
    
    <span class="c">### START CODE HERE ###</span>
    <span class="c"># Retrieve dimensions from A_prev's shape (≈1 line)  </span>
    <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H_prev</span><span class="p">,</span> <span class="n">n_W_prev</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">)</span> <span class="o">=</span> <span class="n">A_prev</span><span class="o">.</span><span class="n">shape</span>
    
    <span class="c"># Retrieve dimensions from W's shape (≈1 line)</span>
    <span class="p">(</span><span class="n">f</span><span class="p">,</span> <span class="n">f</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">,</span> <span class="n">n_C</span><span class="p">)</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">shape</span>
    
    <span class="c"># Retrieve information from "hparameters" (≈2 lines)</span>
    <span class="n">stride</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">"stride"</span><span class="p">]</span>
    <span class="n">pad</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">"pad"</span><span class="p">]</span>
    
    <span class="c"># Compute the dimensions of the CONV output volume using the formula given above. Hint: use int() to floor. (≈2 lines)</span>
    <span class="n">n_H</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">int</span><span class="p">((</span><span class="n">n_H_prev</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">pad</span><span class="o">-</span><span class="n">f</span><span class="p">)</span><span class="o">/</span><span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">n_W</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">int</span><span class="p">((</span><span class="n">n_W_prev</span><span class="o">+</span><span class="mi">2</span><span class="o">*</span><span class="n">pad</span><span class="o">-</span><span class="n">f</span><span class="p">)</span><span class="o">/</span><span class="n">stride</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    
    <span class="c"># Initialize the output volume Z with zeros. (≈1 line)</span>
    <span class="n">Z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span><span class="n">n_H</span><span class="p">,</span><span class="n">n_W</span><span class="p">,</span><span class="n">n_C</span><span class="p">))</span>
    
    <span class="c"># Create A_prev_pad by padding A_prev</span>
    <span class="n">A_prev_pad</span> <span class="o">=</span> <span class="n">zero_pad</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">pad</span><span class="p">)</span>
    
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>                               <span class="c"># loop over the batch of training examples</span>
        <span class="n">a_prev_pad</span> <span class="o">=</span> <span class="n">A_prev_pad</span><span class="p">[</span><span class="n">i</span><span class="p">,:,:,:]</span>                              <span class="c"># Select ith training example's padded activation</span>
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_H</span><span class="p">):</span>                           <span class="c"># loop over vertical axis of the output volume</span>
            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_W</span><span class="p">):</span>                       <span class="c"># loop over horizontal axis of the output volume</span>
                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_C</span><span class="p">):</span>                   <span class="c"># loop over channels (= #filters) of the output volume</span>
                    
                    <span class="c"># Find the corners of the current "slice" (≈4 lines)</span>
                    <span class="n">vert_start</span> <span class="o">=</span> <span class="n">h</span><span class="o">*</span><span class="n">stride</span>
                    <span class="n">vert_end</span> <span class="o">=</span> <span class="n">vert_start</span> <span class="o">+</span> <span class="n">f</span>
                    <span class="n">horiz_start</span> <span class="o">=</span> <span class="n">w</span><span class="o">*</span><span class="n">stride</span>
                    <span class="n">horiz_end</span> <span class="o">=</span> <span class="n">horiz_start</span> <span class="o">+</span> <span class="n">f</span>
                    
                    <span class="c"># Use the corners to define the (3D) slice of a_prev_pad (See Hint above the cell). (≈1 line)</span>
                    <span class="n">a_slice_prev</span> <span class="o">=</span> <span class="n">a_prev_pad</span><span class="p">[</span><span class="n">vert_start</span><span class="p">:</span><span class="n">vert_end</span><span class="p">,</span><span class="n">horiz_start</span><span class="p">:</span><span class="n">horiz_end</span><span class="p">,:]</span>
                    
                    <span class="c"># Convolve the (3D) slice with the correct filter W and bias b, to get back one output neuron. (≈1 line)</span>
                    <span class="n">Z</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">conv_single_step</span><span class="p">(</span><span class="n">a_slice_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">[:,:,:,</span><span class="n">c</span><span class="p">],</span> <span class="n">b</span><span class="p">[:,:,:,</span><span class="n">c</span><span class="p">])</span>
                    <span class="c"># 这一步很容易写错成Z[i, h, w, c] = conv_single_step(a_slice_prev, W, b)</span>
                                        
    <span class="c">### END CODE HERE ###</span>
    
    <span class="c"># Making sure your output shape is correct</span>
    <span class="k">assert</span><span class="p">(</span><span class="n">Z</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">,</span> <span class="n">n_C</span><span class="p">))</span>
    
    <span class="c"># Save information in "cache" for the backprop</span>
    <span class="n">cache</span> <span class="o">=</span> <span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">)</span>
    
    <span class="k">return</span> <span class="n">Z</span><span class="p">,</span> <span class="n">cache</span>
</code></pre></div></div>

<h1 id="graded-function-pool_forward">GRADED FUNCTION: pool_forward</h1>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">pool_forward</span><span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">,</span> <span class="n">mode</span> <span class="o">=</span> <span class="s">"max"</span><span class="p">):</span>
    <span class="s">"""
    Implements the forward pass of the pooling layer
    
    Arguments:
    A_prev -- Input data, numpy array of shape (m, n_H_prev, n_W_prev, n_C_prev)
    hparameters -- python dictionary containing "f" and "stride"
    mode -- the pooling mode you would like to use, defined as a string ("max" or "average")
    
    Returns:
    A -- output of the pool layer, a numpy array of shape (m, n_H, n_W, n_C)
    cache -- cache used in the backward pass of the pooling layer, contains the input and hparameters 
    """</span>
    
    <span class="c"># Retrieve dimensions from the input shape</span>
    <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H_prev</span><span class="p">,</span> <span class="n">n_W_prev</span><span class="p">,</span> <span class="n">n_C_prev</span><span class="p">)</span> <span class="o">=</span> <span class="n">A_prev</span><span class="o">.</span><span class="n">shape</span>
    
    <span class="c"># Retrieve hyperparameters from "hparameters"</span>
    <span class="n">f</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">"f"</span><span class="p">]</span>
    <span class="n">stride</span> <span class="o">=</span> <span class="n">hparameters</span><span class="p">[</span><span class="s">"stride"</span><span class="p">]</span>
    
    <span class="c"># Define the dimensions of the output</span>
    <span class="n">n_H</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">n_H_prev</span> <span class="o">-</span> <span class="n">f</span><span class="p">)</span> <span class="o">/</span> <span class="n">stride</span><span class="p">)</span>
    <span class="n">n_W</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="p">(</span><span class="n">n_W_prev</span> <span class="o">-</span> <span class="n">f</span><span class="p">)</span> <span class="o">/</span> <span class="n">stride</span><span class="p">)</span>
    <span class="n">n_C</span> <span class="o">=</span> <span class="n">n_C_prev</span>
    
    <span class="c"># Initialize output matrix A</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">,</span> <span class="n">n_C</span><span class="p">))</span>              
    <span class="c">### START CODE HERE ###</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">m</span><span class="p">):</span>                         <span class="c"># loop over the training examples</span>
        <span class="k">for</span> <span class="n">h</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_H</span><span class="p">):</span>                     <span class="c"># loop on the vertical axis of the output volume</span>
            <span class="k">for</span> <span class="n">w</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_W</span><span class="p">):</span>                 <span class="c"># loop on the horizontal axis of the output volume</span>
                <span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="nb">range</span> <span class="p">(</span><span class="n">n_C</span><span class="p">):</span>            <span class="c"># loop over the channels of the output volume</span>
                    
                    <span class="c"># Find the corners of the current "slice" (≈4 lines)</span>
                    <span class="n">vert_start</span> <span class="o">=</span> <span class="n">h</span><span class="o">*</span><span class="n">stride</span> 
                    <span class="n">vert_end</span> <span class="o">=</span> <span class="n">h</span><span class="o">*</span><span class="n">stride</span> <span class="o">+</span> <span class="n">f</span>
                    <span class="n">horiz_start</span> <span class="o">=</span> <span class="n">w</span><span class="o">*</span><span class="n">stride</span>
                    <span class="n">horiz_end</span> <span class="o">=</span> <span class="n">w</span><span class="o">*</span><span class="n">stride</span> <span class="o">+</span> <span class="n">f</span>
                    
                    <span class="c"># Use the corners to define the current slice on the ith training example of A_prev, channel c. (≈1 line)</span>
                    <span class="n">a_prev_slice</span> <span class="o">=</span> <span class="n">A_prev</span><span class="p">[</span><span class="n">i</span><span class="p">,</span><span class="n">vert_start</span><span class="p">:</span><span class="n">vert_end</span><span class="p">,</span><span class="n">horiz_start</span><span class="p">:</span><span class="n">horiz_end</span><span class="p">,</span><span class="n">c</span><span class="p">]</span>
                    <span class="c"># 这里容易写错为a_prev_slice = a_prev[vert_start:vert_end,horiz_start:horiz_end,:]</span>

                    <span class="c"># Compute the pooling operation on the slice. Use an if statment to differentiate the modes. Use np.max/np.mean.</span>
                    <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s">"max"</span><span class="p">:</span>
                        <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="nb">max</span><span class="p">(</span><span class="n">a_prev_slice</span><span class="p">)</span>
                    <span class="k">elif</span> <span class="n">mode</span> <span class="o">==</span> <span class="s">"average"</span><span class="p">:</span>
                        <span class="n">A</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">c</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">a_prev_slice</span><span class="p">)</span>
    
    <span class="c">### END CODE HERE ###</span>
    
    <span class="c"># Store the input and hparameters in "cache" for pool_backward()</span>
    <span class="n">cache</span> <span class="o">=</span> <span class="p">(</span><span class="n">A_prev</span><span class="p">,</span> <span class="n">hparameters</span><span class="p">)</span>
    
    <span class="c"># Making sure your output shape is correct</span>
    <span class="k">assert</span><span class="p">(</span><span class="n">A</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">m</span><span class="p">,</span> <span class="n">n_H</span><span class="p">,</span> <span class="n">n_W</span><span class="p">,</span> <span class="n">n_C</span><span class="p">))</span>
    
    <span class="k">return</span> <span class="n">A</span><span class="p">,</span> <span class="n">cache</span>
</code></pre></div></div>

<h2 id="aplication-on-tensorflow">Aplication on Tensorflow</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="c">### START CODE HERE ### (≈2 lines)</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_H0</span><span class="p">,</span> <span class="n">n_W0</span><span class="p">,</span> <span class="n">n_C0</span><span class="p">))</span>
    <span class="n">Y</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">placeholder</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">,</span> <span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="bp">None</span><span class="p">,</span> <span class="n">n_y</span><span class="p">))</span>
    <span class="c">### END CODE HERE ###</span>

    <span class="c">### START CODE HERE ### (approx. 2 lines of code)</span>
    <span class="n">W1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">"W1"</span><span class="p">,</span> <span class="p">[</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span><span class="mi">8</span><span class="p">],</span> <span class="n">initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span><span class="p">))</span>
    <span class="n">W2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">get_variable</span><span class="p">(</span><span class="s">"W2"</span><span class="p">,</span> <span class="p">[</span><span class="mi">2</span><span class="p">,</span><span class="mi">2</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">16</span><span class="p">],</span> <span class="n">initializer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">xavier_initializer</span><span class="p">(</span><span class="n">seed</span> <span class="o">=</span> <span class="mi">0</span><span class="p">))</span>
    <span class="c">### END CODE HERE ###</span>

<span class="c"># GRADED FUNCTION: forward_propagation</span>

<span class="k">def</span> <span class="nf">forward_propagation</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">parameters</span><span class="p">):</span>
    <span class="s">"""
    Implements the forward propagation for the model:
    CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; CONV2D -&gt; RELU -&gt; MAXPOOL -&gt; FLATTEN -&gt; FULLYCONNECTED
    
    Arguments:
    X -- input dataset placeholder, of shape (input size, number of examples)
    parameters -- python dictionary containing your parameters "W1", "W2"
                  the shapes are given in initialize_parameters

    Returns:
    Z3 -- the output of the last LINEAR unit
    """</span>
    
    <span class="c"># Retrieve the parameters from the dictionary "parameters" </span>
    <span class="n">W1</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s">'W1'</span><span class="p">]</span>
    <span class="n">W2</span> <span class="o">=</span> <span class="n">parameters</span><span class="p">[</span><span class="s">'W2'</span><span class="p">]</span>
    
    <span class="c">### START CODE HERE ###</span>
    <span class="c"># CONV2D: stride of 1, padding 'SAME'</span>
    <span class="n">Z1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">W1</span><span class="p">,</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span> <span class="o">=</span> <span class="s">'SAME'</span><span class="p">)</span>
    <span class="c"># RELU</span>
    <span class="n">A1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">Z1</span><span class="p">)</span>
    <span class="c"># MAXPOOL: window 8x8, sride 8, padding 'SAME'</span>
    <span class="n">P1</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">A1</span><span class="p">,</span> <span class="n">ksize</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">8</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span> <span class="o">=</span> <span class="s">'SAME'</span><span class="p">)</span>
    <span class="c"># CONV2D: filters W2, stride 1, padding 'SAME'</span>
    <span class="n">Z2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">conv2d</span><span class="p">(</span><span class="n">P1</span><span class="p">,</span><span class="n">W2</span><span class="p">,</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span> <span class="o">=</span> <span class="s">'SAME'</span><span class="p">)</span>
    <span class="c"># RELU</span>
    <span class="n">A2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">relu</span><span class="p">(</span><span class="n">Z2</span><span class="p">)</span>
    <span class="c"># MAXPOOL: window 4x4, stride 4, padding 'SAME'</span>
    <span class="n">P2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">max_pool</span><span class="p">(</span><span class="n">A2</span><span class="p">,</span> <span class="n">ksize</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">strides</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">4</span><span class="p">,</span><span class="mi">1</span><span class="p">],</span> <span class="n">padding</span> <span class="o">=</span> <span class="s">'SAME'</span><span class="p">)</span>
    <span class="c"># FLATTEN</span>
    <span class="n">P2</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">P2</span><span class="p">)</span>
    <span class="c"># FULLY-CONNECTED without non-linear activation function (not not call softmax).</span>
    <span class="c"># 6 neurons in output layer. Hint: one of the arguments should be "activation_fn=None" </span>
    <span class="n">Z3</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">contrib</span><span class="o">.</span><span class="n">layers</span><span class="o">.</span><span class="n">fully_connected</span><span class="p">(</span><span class="n">P2</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="n">activation_fn</span><span class="o">=</span><span class="bp">None</span><span class="p">)</span>
    <span class="c">### END CODE HERE ###</span>

    <span class="k">return</span> <span class="n">Z3</span>



</code></pre></div></div>

</p>
	</div>

</section>
</div>


<!-- Footer -->
	<footer id="footer">
		<div class="inner">
			<ul class="icons">
				
				
				<li><a href="http://weibo.com/u/2377304267" class="icon alt fa-weibo" target="_blank"><span class="label">weibo</span></a></li>
				
				
				<li><a href="https://www.facebook.com/profile.php?id=100009585159226" class="icon alt fa-facebook" target="_blank"><span class="label">Facebook</span></a></li>
				
				
				<li><a href="https://www.instagram.com/harryliuxin/" class="icon alt fa-instagram" target="_blank"><span class="label">Instagram</span></a></li>
				
				
				
				
				
				<li><a href="http://www.miaopai.com/u/wxsso_p4mslofx14" class="icon alt fa-video-camera" target="_blank"><span class="label">video</span></a></li>
				
				
				<li><a href="https://www.linkedin.com/in/xin-liu-868501134" class="icon alt fa-linkedin" target="_blank"><span class="label">LinkedIn</span></a></li>
				
			</ul>
			<ul class="copyright">
				<li>&copy; LiuXin </li>
				<li> stay hungry, stay foolish</li>
				<li>Designed by: <a href="https://liuxin.in/about/" target="_blank">刘鑫</a></li>

			</ul>
		</div>
	</footer>

	

</body>

</html>