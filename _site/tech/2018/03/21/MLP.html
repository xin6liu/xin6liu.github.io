<!DOCTYPE html>

<html>

<head>
	<title>LiuXin</title>
	<meta charset="utf-8" />
	<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
	<!--[if lte IE 8]><script src="http://localhost:4000/assets/js/ie/html5shiv.js"></script><![endif]-->
	<link rel="stylesheet" href="/assets/css/main_new.css">
	<link rel="stylesheet" href="/assets/css/syntax.css">
	<!--[if lte IE 9]><link rel="stylesheet" href="http://localhost:4000/assets/css/ie9.css" /><![endif]-->
	<!--[if lte IE 8]><link rel="stylesheet" href="http://localhost:4000/assets/css/ie8.css" /><![endif]-->
	<!-- <script type="text/javascript"
  src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
	</script> -->
	<script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
	<script>
		MathJax = {
		  tex: {
			inlineMath: [['$', '$'], ['\\(', '\\)']]
		  }
		};
	</script>
	<script id="MathJax-script" async
	src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
	</script>
</head>


<body>

<!-- Wrapper -->
<div id="wrapper">

<!-- Header -->
<header id="header"	
					>
	<a href="http://localhost:4000/" class="logo"><strong>LiuXin</strong> <span>stay hungry, stay foolish</span></a>
	<nav>
		<a href="#menu">Menu</a>
	</nav>
</header>

<!-- Menu -->
<nav id="menu">
	<ul class="links">
		
		
			
				<li><a href="/home/1python.html">网页开发 Web Development</a></li>
			
		
			
				<li><a href="/home/2ai.html">机器学习 Machine Learning</a></li>
			
		
			
				<li><a href="/home/3cfd.html">计算流体力学 CFD</a></li>
			
		
			
				<li><a href="/home/4cs.html">计算机科学 Computer Science</a></li>
			
		
			
				<li><a href="/home/5mns.html">纳米科学 Nanoscience</a></li>
			
		
			
				<li><a href="/home/6course.html">课程 Course</a></li>
			
		
			
				<li><a href="/home/7diary.html">生活 Diary</a></li>
			
		
			
				<li><a href="/home/8categories.html">标签 tags</a></li>
			
		
	</ul>
	<!-- <ul class="actions vertical">
		<li><a href="#" class="button special fit">Get Started</a></li>
		<li><a href="#" class="button fit">Log In</a></li>
	</ul> -->
</nav> 
    
    
<!-- Main -->
<div id="main" class="alt">

<!-- One -->
<section id="one">
	<div class="inner">
		<header class="major">
<!-- title -->
			<h1>反向传播算法</h1>
<!-- 日期 -->		
		
		2018-03-21
		
		</header>
<!-- description -->	
		<h5></h5>
<!-- 图片 -->		
		<!-- 
		 -->
<!-- 正文 -->
		<p><script type="text/javascript" async="" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML">
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
</script>

<ul>
  <li>刘鑫</li>
  <li>2018.03.21</li>
</ul>

<p><strong>多层感知器</strong>（Multilayer Perceptron,缩写MLP）是一种最常见的前向结构的人工神经网络(前馈神经网络)。</p>

<p><strong>反向传播算法</strong>的监督学习方法常被用来训练MLP, 下面是反向传播算法的笔记。</p>

<blockquote>
  <p>传送门：</p>

  <p><a href="http://liuxin21.com/python,%20cs/2018/03/12/sklearn.html">numpy, pandas, seaborn, sklearn 基础</a></p>

  <p><a href="http://ibillxia.github.io/blog/2013/03/24/classes-of-neural-networks/">神经网络模型分类</a></p>

  <p><a href="http://liuxin21.com/ai/2018/03/18/ai.html">神经网络基础</a></p>
</blockquote>

<p>在之前的文章中提到了神经网络<code>model</code>, 衡量<code>model</code>性能的损失函数$J(\theta)$, 使$J(\theta)$减小的学习算法<code>learn</code>(梯度下降算法)。</p>

<p>这一次我们来探讨<strong>梯度下降</strong>这个<code>learn</code>中，如何求$J(\theta)$的梯度。</p>

<p>我们用到的就是——<strong>反向传播算法（backpropogate algorithm）</strong>。</p>

<h2 id="反向传播算法-和-链式法则">反向传播算法 和 “链式法则”</h2>

<p>我们考虑只有两个网络层和一个输出层，第一层（输入层）只有两个节点，第二层只有一个节点的情况：</p>

<p><img src="https://i.imgur.com/lPgoVkz.png" alt="Screenshot 2018-03-21 16.43.56" /></p>

<p>其中，$\theta$ 为 $w_{11}, w_{12}, \mathrm{bias}_1$ 中的一个，$x$ 为
$\left[
\begin{matrix}
a_1 <br />
a_2 
\end{matrix}
\right]$
。
根据链式法则：</p>

<p><img src="https://i.imgur.com/GFY4Jy7.png" alt="Screenshot 2018-03-21 16.44.16" /></p>

<p>其中，</p>

<p><img src="https://i.imgur.com/MG2BDUZ.png" alt="Screenshot 2018-03-21 16.53.44" /></p>

<p>举个栗子：</p>

<p><img src="https://i.imgur.com/ObTOvDi.png" alt="Screenshot 2018-03-21 16.44.16 copy" /></p>

<h2 id="python-代码实现">Python 代码实现</h2>

<pre><code class="language-python">import numpy as np
</code></pre>

<pre><code class="language-python">class C1:
    
    def __init__(self, lx, ly):
        '''
        这里的输入层(a1,a2)的长度lx=2, 输出层(b1)的长度ly=1
        weight矩阵就是1X2, bias就是1X1 
        '''   
        self.weights = np.random.randn(ly,lx)
        self.bias = np.random.randn(ly)


    def forward(self, x):
        '''
        输入：输入层x(a1,a2)
        返回：输出层y(b1)
        '''
        self.x = x
        self.y = np.dot(self.weights, x) + self.bias
        return self.y

    def backward(self, d):
        '''
        输入：导数值d
        返回：参数w的梯度dw
        '''
        self.dw = d * self.x
        # self.db = d
        # self.dx = d * self.weights
        return self.dw
</code></pre>

<p>上面的代码的三个def完成了三个工作：</p>
<ol>
  <li>随机初始化网络参数w和bias</li>
  <li>输入x，计算出这层的y，向前传递给下一层</li>
  <li>将前面层向后传递的导数值与这一层的x想乘，得到最后一层对本层参数$\theta$的梯度</li>
</ol>

<p>然后进行sigmoid层：</p>

<pre><code class="language-python">class C2:
    def __init__(self):
        pass
    
    def sigmoid(self, x):
        return 1/(1 + np.exp(-x))
    
    def forward(self, x):
        self.x = x
        self.y = self.sigmoid(x)
        return self.y
    
    def backward(self):
        sig = self.sigmoid(self.x)
        self.dx = sig*(1-sig)
        return self.dx
</code></pre>

<p>把上面两层拼起来，就完成了整体的网络结构：</p>

<pre><code class="language-python">def main():
    c1 = C1(2,1)
    c2 = C2()
    x = np.array([[1],[2]])
    print(c1.weights, c1.bias, x)
    
    y1 = c1.forward(x)
    y2 = c2.forward(y1)
    print(y1, y2)
    
    dh = c2.backward()
    dw = c1.backward(dh)
    print(dh, dw)
    
if __name__ == '__main__':
    main()
</code></pre>
<pre><code class="language-python">    [[-1.07906824 -0.42675882]] [ 0.2913231] [[1]
     [2]]
    [[-1.64126277]] [[ 0.16229331]]
    [[ 0.13595419]] [[ 0.13595419]
     [ 0.27190838]]
</code></pre>
</p>
	</div>

</section>
</div>


<!-- Footer -->
	<footer id="footer">
		<div class="inner">
			<ul class="icons">
				
				
				<li><a href="http://weibo.com/u/2377304267" class="icon alt fa-weibo" target="_blank"><span class="label">weibo</span></a></li>
				
				
				<li><a href="https://www.facebook.com/profile.php?id=100009585159226" class="icon alt fa-facebook" target="_blank"><span class="label">Facebook</span></a></li>
				
				
				<li><a href="https://www.instagram.com/harryliuxin/" class="icon alt fa-instagram" target="_blank"><span class="label">Instagram</span></a></li>
				
				
				
				
				
				<li><a href="http://www.miaopai.com/u/wxsso_p4mslofx14" class="icon alt fa-video-camera" target="_blank"><span class="label">video</span></a></li>
				
				
				<li><a href="https://www.linkedin.com/in/xin-liu-868501134" class="icon alt fa-linkedin" target="_blank"><span class="label">LinkedIn</span></a></li>
				
			</ul>
			<ul class="copyright">
				<li>&copy; LiuXin </li>
				<li> stay hungry, stay foolish</li>
				<li>Designed by: <a href="https://liuxin.in/about/" target="_blank">刘鑫</a></li>

			</ul>
		</div>
	</footer>

	

</body>

</html>